## 背景介绍

在维护Ceph集群的过程中, 因为某一块磁盘故障而下线OSD是很常见的事情, 下线的意思是永久关闭, 不是临时关闭, 这里记录一下操作过程.

## 操作过程

1. 移出OSD
移出后OSD后, Ceph集群就会重新rebalance数据

```
ceph osd out osd.<id>
```

操作完以后要等待Ceph集群重新平衡完成后再继续, 可以使用如下命令观察:

```
# ceph -s 

主要关注两个点:

1. health: HEALTH_OK
2. 正在进行重平衡的进度
  progress:
    Rebalancing after osd.0 marked out (5m)
      [=================...........] (remaining: 3m)
    Rebalancing after osd.3 marked out (2m)
      [===========.................] (remaining: 4m)

```


2. 停止并删除该OSD进程

可以在有ceph命令的节点上执行如下:
```
ceph orch daemon stop osd.<id>
ceph orch daemon rm osd.<id> --force
```


3. 从集群中删除该OSD的记录

```
ceph osd purge osd.<id> --yes-i-really-mean-it
```

这个命令会：
	•	删除集群元数据中的该 OSD
	•	清理 Crush map 中对应的 entry
	•	删除认证 keyring

老版本(Luminous之前, 12之前)没有上述命令, 必须分步骤执行, 因为大部分都是新版本, 老的命令就不记录了, 参考文档即可.


## 参考文档

* [ceph OSD操作](https://docs.ceph.com/en/latest/rados/operations/add-or-rm-osds/)
