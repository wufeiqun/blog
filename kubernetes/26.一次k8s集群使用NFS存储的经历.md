## 背景介绍

之前的工作经历中, kubernetes集群都是采用的云厂商的, 这样的话我的日常工作就是专注于如何使用了, 这对中小企业来说确实是好的选择, 因为不用雇人专门维护复杂的kubernetes集群, 但是事情总是有两面性, 这样我就不能直接接触kubernetes底层的组件, 对kubernetes的学习也不会太深, 毕竟遇到的问题不多.

来到新公司, 这个公司的kubernetes集群都是自建的, 而且运维只有我一个, 需要维护公司好几十个kubernetes集群, 大大小小的问题都会遇到, 这种场景对于我技术可以快速提高, 这里就记录一个工作中遇到的技术的问题.

公司外采了一套系统, 系统所需要的基础组件都是由运维来负责安装搭建, 我来公司的时候, 这些基础服务已经由上一个运维搭建好了, 所以我这边只能先熟悉目前的安装文档, 遇到新问题解决新问题. 公司为了这一套系统准备了一批新机器, 上个运维的同事搭建了一套k8s集群, 所有的服务都是运行在k8s集群上, 包括有状态的和无状态的.

## 问题描述

其中有一个组件是Doris, 采用的是官方的Operator的方式安装, 业务方需要在服务的目录下放一些jdbc的jar包,  官方文档中也推荐log的目录采用外挂存储的方式存放, Operator中已经有一部分可以参考的代码, 也咨询了之前安装的同事, 按照这个代码会自动创建PVC, 不用手工绑定, 所以上述小事儿应该是很简单的.

```yaml
    persistentVolumes:
      - mountPath: /opt/apache-doris/be/storage
        name: be-storage
        persistentVolumeClaimSpec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 800Gi
          storageClassName: openebs-hostpath
      - mountPath: /opt/apache-doris/be/jdbc_drivers
        name: bejdbc
        persistentVolumeClaimSpec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
          storageClassName: doris-config-nfs
```

![Image](https://github.com/user-attachments/assets/d3c5780b-4dc4-45bd-b2a8-1bbbfc2ed73d)

但是事与愿违, 我按照上述思路执行后发现PVC不会自动创建, 而且看POD的报错, 都是挂载的同一个PVC, 名字就是身上面配置的那个`name`, 正常来说是每个POD创建一个PVC, 也就是`name-0`, `name-1`等. 

## 解决过程

当天失败后快速回滚了, 也就是把上述代码删除了, 后来我看了半天的文档, 也没啥问题, 其中有一个提示说磁盘太小的原因,感觉也不太靠谱, 最终认为这是它们的bug, 但是问题总是需要解决的.



#### 手工创建PVC



最开始想到的方法那就是, 它自己不给创建, 那我手工帮它创建喽. 于是就手工创建PVC, 示例代码如下:

```yaml

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: fejdbc-0
  namespace: doris
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: openebs
```



这里我试过两次, 因为Doris是通过statefulset启动的, 每个PVC都有编码, 也就是`pvc-name-{index}`, 我给每个POD对应创建了一个PVC, 最后发现它每个POD挂载的都是相同名字的PVC, 也就是需要创建一个可以支持`ReadWriteOnce`方式的PVC, 但是这个集群搭建的时候采用了obs的hostpath的方式, 也就是存储在每个节点的本地, 不能共享, 而且我对ebs还不太熟悉, 所以也不太敢动这个配置, 于是只能采用其它方式了.



## 采用NFS

如果是在云上的话, 那就很简单了, 选择一个云厂商支持的云盘就可以了, 但是这是自建的, 那就只能采用成熟的NFS的方案了.



我按照https://github.com/kubernetes-csi/csi-driver-nfs这个项目的文档, 采用kubectl的方式安装了v4.11.0版本. 开始以为安装起来很简单, 这都是非常成熟的技术了, 后来发现没那么容易.



####  StorageClass

开始以为安装好以后就自动有了StorageClass, 后来看了文档中的示例代码, 发现还需要自己创建这个,  而且可以配置多个不同的StorageClass, 示例如下:



```
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: test # 起一个名字, 比如nfs-storage
provisioner: nfs.csi.k8s.io
parameters:
  server: 192.168.1.1 # NFS服务地址
  share: / # NFS共享路径
reclaimPolicy: Delete # PVC删除后, 对应的PV是否保留
volumeBindingMode: Immediate # 申请后是否马上创建还是等有POD消费的时候再创建
allowVolumeExpansion: true # 是否允许扩容
mountOptions:
  - nfsvers=4.1 # 额外参数, 版本
```



#### 替换镜像

遇到的第一个问题就是国内需要把配置文件中所有的镜像都要替换成国内的源, 也就是需要从国外下载下来, 然后上传的国内的私服仓库, 这个虽然比较繁琐, 但是还好没有什么技术难点, 多花点时间而已.



#### kubelet目录问题



修改完镜像以后我就直接安装, 结果POD启动失败, 提示我找不到`/var/lib/kubelet`, 我去node节点上查看了, 发现kubelet的家目录确实改成了`/data/kubelet`,  又去安装的目录确认了下:

```
cat /root/kubeadm-ha/example/hosts.m-master.hostname.ini

...省略...
; 若服务器磁盘分为系统盘与数据盘，请修改以下路径至数据盘自定义的目录。
; Kubelet 根目录
kubelet_root_dir="/data/kubelet"
; docker容器存储目录
docker_storage_dir="/data/docker"
; containerd容器存储目录
containerd_storage_dir="/data/containerd"
; Etcd 数据根目录
etcd_data_dir="/var/lib/etcd"
```



这里其实是kubernetes中经常遇到的一个问题, `/var/lib/kubelet`磁盘容易满, 这里有3个常见的解决方法:

* 根分区分配大一些
* 单独挂载一个磁盘给`/var/lib/kubelet`
* 单独挂载磁盘到一个目录比如`data`, 安装集群的时候修改kubelet的家目录



|                           方案介绍                           |      优点      |                             缺点                             |
| :----------------------------------------------------------: | :------------: | :----------------------------------------------------------: |
|                   方案一, 根分区分配大一些                   |    简单粗暴    |  磁盘容易因为某一个POD而爆满, 达摩克利斯之剑, 适合测试环境   |
|         方案二, 单独挂载一个磁盘给`/var/lib/kubelet`         | 适合新安装集群 |                                                              |
| 方案三, 单独挂载磁盘到一个目录比如`data`, <br />安装集群的时候修改kubelet的家目录 |                | CSI插件目录都是默认的/var/lib/kubelet, 如果调整的话, 可能有问题 |
|                                                              |                |                                                              |



整体上我比较认可第二种方案, 这次的情况是采用了第三种方案, 也就是修改了kubelet的家目录, 这样在往集群安装CSI插件的时候就要修改相关的路径. 修改这些底层软件的配置谈何容易, 特别是在短时间内业务方就需要的情况下, 一不小心就会给未来埋坑, 这里是我找到的配置涉及到kubelet目录的地方:

```bash

# grep -nr '/kubelet' *
csi-nfs-controller.yaml:174:              mountPath: /var/lib/kubelet/pods
csi-nfs-controller.yaml:187:            path: /data/kubelet/pods
csi-nfs-node.yaml:62:              value: /data/kubelet/plugins/csi-nfsplugin/csi.sock
csi-nfs-node.yaml:117:              mountPath: /data/kubelet/pods
csi-nfs-node.yaml:128:            path: /data/kubelet/plugins/csi-nfsplugin
csi-nfs-node.yaml:132:            path: /data/kubelet/pods
csi-nfs-node.yaml:135:            path: /data/kubelet/plugins_registry
```



这么多的地方到底哪个该修改, 哪个不该修改, 对于第一次接触的话, 也不太容易短时间内决策, 只能尝试. 在kubernetes中有volumns和volumnmounts两个配置, volumns就是一块磁盘, 这里就是指的NFS提供的磁盘, 因为NFS会挂载到POD运行的node节点, 所以这里肯定是需要把/var/lib/kubelet改成/data/kubelet的, 但是volumnmoounts是POD里面的挂载的配置, 我开始想的是不用修改, 于是我就尝试了一下.



我创建了一个PVC, 然后又创建了一个简单的Deployment来使用这个PVC:



```yaml

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wufeiqun
  namespace: doris
spec:
  replicas: 1
  selector:
    matchLabels:
      name: wufeiqun
  template:
    metadata:
      name: wufeiqun
      labels:
        name: wufeiqun
    spec:
      containers:
        - name: wufeiqun
          image: nginx:latest
          volumeMounts:
            - name: nfs
              mountPath: "/mnt/nfs"
              readOnly: false
      volumes:
        - name: nfs
          persistentVolumeClaim:
            claimName: fejdbc
```



开始时看到nfs的POD有超时的错误:

```
E0521 02:10:28.934308       1 mount_linux.go:282] Mount failed: exit status 32
Mounting command: mount
Mounting arguments: -t nfs -o nfsvers=4.1 xxx.xxx.xxx.xxx:/opt/doris_config_file_nfs /tmp/pvc-43c079e4-da1c-45cb-832b-839c21657d19
Output: mount.nfs: No route to host

E0521 02:11:24.704440       1 utils.go:116] GRPC error: rpc error: code = Internal desc = failed to mount nfs server: rpc error: code = Internal desc = time out
I0521 02:11:24.705756       1 utils.go:111] GRPC call: /csi.v1.Controller/CreateVolume
```

最开始以为又踩了什么底层的坑, 也就放了一放去做别事情了, 后来从新思考的时候我注意到了创建StorageClass的时候, 里面有一个额外的参数:

```
nfsvers=4.1 # 额外参数, 版本
```

我想, 是不是因为NFS的服务端的版本不是4, 所以我搜索了一下如何查看NFS版本的命令, 发现服务端是支持4版本的, 检查的命令如下:

```
root@localhost:~# rpcinfo -p localhost | grep nfs
    100003    3   tcp   2049  nfs
    100003    4   tcp   2049  nfs
```



我意外发现新版本的NFS监听的端口是`2049`, 以前的版本都是`111`, 我又尝试去容器的POD中telnet了一下, 果然发现不通, 因为都是同一个内网, 那指定是防火墙的问题了, 于是登录NFS那个服务器查看了一下, 果然实锤了, 这个NFS是之前同事安装的, 我看已经有了就没有重新搭建, 原来这里也有坑.

![Image](https://github.com/user-attachments/assets/5ca64f6c-9fa1-4a5f-8221-7b5350eda56f)



你以为到这里就结束了, NO, NO, NO!



#### NFS目录不共享问题

我解决完上述问题后, 直接给Doris配置了相关的磁盘的配置, 以为重启后就会大功告成, 结果磁盘确实挂载上去了, 从lens上看, PVC确实是被多个POD绑定了, 结果我进去一个POD的绑定目录下载文件后再其它的POD看不到, 在NFS服务器上也看不到, 奇了怪了, 我就是想着往每个POD里面下载好那些jdbc文件, 如果重启后依然还在,那么也是没有问题的.



结果我重启后, POD一直卡在Terminating状态, 等了好几分钟都不行, 按说超时后会被强制杀死, 结果也是没有, 报的错误也是没啥相关的:

![Image](https://github.com/user-attachments/assets/a2ff0705-63af-4d30-a257-bfc36c63a397)



后来在咨询了ChatGPT后, 它让我尝试登录node节点查看kubelet的日志,  我看了日志后确实有错误日志, 而且是NFS挂载相关的, 这时候我确认了, 还是因为NFS的配置的问题, 于是就强制杀死了一下该POD后从新排查:

```
kubectl delete pod <pod-name> --grace-period=0 --force
```



我又去看了下安装nfs的那些yaml文件, 找了一下里面包干kubelet目录的部分, 找了那些还没有修改成/data/kubelet的位置咨询了下ChatGPT, 配置如下:



```yaml
- name: pods-mount-dir
    mountPath: /var/lib/kubelet/pods
    mountPropagation: "Bidirectional"
```

ChatGPT的回答中正好是我当前遇到的场景:

![Image](https://github.com/user-attachments/assets/1dc2736a-6740-40bf-96e8-73edf2de0891)



我继续追问, 我修改了kubelet的家目录后该如何修改, ChatGPT给的答案完美命中, 太强了.

 ![Image](https://github.com/user-attachments/assets/e6666239-b873-4322-8be8-1f3143bc2151)



最终我把上述参数修改后重新创建PVC后, 完美解决.



## 总结

一些感悟:

* ChatGPT是非常强大的工具, 一定要充分利用
* 你要给ChatGPT尽可能多的上下文, 告诉你的目标的更多背景信息
* 尽可能把问题拆分的细一些
* 不要放弃任何疑点
