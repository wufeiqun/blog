## 背景介绍

前一段时间在公司遇到一次因为MySQL的死锁导致故障的情况, 现象基本上是服务不可用, 也就是访问服务超时, 重启了服务很多次, 一直不好, 最后开发同学查询数据库发现有死锁, 杀死后服务就恢复了. 

我没有想到这个点, 因为这块之前遇到的比较少, 是我的知识盲区, 于是趁这个机会, 学习了一下MySQL的死锁相关的知识, 偏向于如何监控和发现, 至于如何解决, 这块是需要跟研发同学一起配合的.

## 常见的死锁的原因

* 事务顺序不一致

我自己能够想到, 并且看网上文章比较多的是`事务顺序不一致`: 事务A锁资源1后请求资源2, 事务B锁资源2后请求资源1.


其它的也有, 我暂时没遇到, 第一时间也没想起来, 暂时不做记录, 这里以`事务顺序不一致`为例来说明.

## 模拟一个死锁

创建一个`test`表:

```
CREATE TABLE `test` (
  `id` int(11) NOT NULL,
  `value` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

INSERT INTO test VALUES (1,1),(2,2);
```



按照行顺序执行如下命令:

| SessionA                                              | SessionB                                                     |
| ----------------------------------------------------- | ------------------------------------------------------------ |
| BEGIN;<br />UPDATE test SET value = 123 WHERE id = 1; |                                                              |
|                                                       | BEGIN;<br/>UPDATE test SET value = 321 WHERE id = 2;         |
| UPDATE test SET value = 123 WHERE id = 2;             |                                                              |
|                                                       | UPDATE test SET value = 321 WHERE id = 1;                    |
|                                                       | ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction |



## 使用pt-deadlock-logger检测死锁

执行如下命令

1. 持续运行并每5秒钟探测一次死锁, 有新的死锁会打印
2. 死锁信息会输出到控制台
3.  默认显示最近一次发生的死锁信息

> 注意MySQL连接地址/账号/密码之间不要有空格

```
pt-deadlock-logger h=192.168.1.1,P=3306,u=root,p=xxx --interval 5 
```

```
server：发生死锁的（源）服务器
ts：上次检测到死锁的日期和时间
thread：GreatSQL 线程编号，和 SHOW FULL PROCESSLIST 中的 ID 一致
txn_id：InnoDB 事务 ID
txn_time：发生死锁时事务处于活动状态的时间
user：连接的数据库用户名
hostname：连接的主机
ip：连接的 IP 地址。如果指定 --numeric-ip，则将转换为无符号整数
db：发生死锁的库
tbl：发生死锁的表
idx：发生死锁的索引
lock_type：导致死锁的锁上持有的事务的类型
lock_mode：导致死锁的锁的锁定模式
wait_hold：事务是在等待锁还是持有锁
victim：事务是否被选为死可回滚的事务并进行回滚
query：导致死锁的查询
```

示例输出:

```
server ts thread txn_id txn_time user hostname ip db tbl idx lock_type lock_mode wait_hold victim query
192.168.1.1 2025-12-17T14:36:51 516958 0 75 root  10.80.11.208 wufeiqun test PRIMARY RECORD X w 0 update test set value=321 where id=2
192.168.1.1 2025-12-17T14:36:51 516960 0 37 root  10.80.11.208 wufeiqun test PRIMARY RECORD X w 1 update test set value=123 where id=1

```



从这里可以清除看到发生死锁的两个SQL语句, 并且也能看到哪个事务被回滚了, victim表示谁是受害者, MySQL默认会把该事务进行回滚, 也就是成本最小的被回滚, 而且只要遇到死锁就会有事务被回滚, 因为有一个参数`innodb_deadlock_detect`默认是开启的, 所以死锁默出现后默认会被检测并处理.

## 一些思考

1. 出现死锁是不是一定会影响业务?

根据实际情况的观测, 不是的. 一般情况下, 出现死锁的时候, MySQL会根据自己的判断回滚其中一个事务, 也就是其中一个事务会执行失败, 只要业务上做好重试的话, 是不会影响业务正常运行的. 如果业务没有做好重试, 那就会影响失败的这次事务, 这个影响面积不大, 开发者通过报错可以很容易判断并解决.

如果服务是一个高并发请求的场景, 出现死锁的话, 因为需要等待MySQL检测并处理, 这个是需要一定时间的, 高并发场景下就会导致MySQL待处理任务的挤压, 就会出现大面积的请求阻塞, 想象一下路上出现交通事故的时候, 即使交警会马上去处理, 那也会对交通产生一定影响的. 这时候一方面可以通过查看MySQL出现的死锁数量来初步判断, 另一方面也可以通过线程池使用率来判断, 锁等待时间长的话, 会消耗更多的线程去处理.

访问表的时候如果顺序不一致就容易产生死锁, 还是要**同一类业务，访问表的顺序必须一致**, 比如加上`order by id`等





2. 若何通过prometheus+mysqlExporter检测死锁?

`mysql_info_schema_innodb_metrics_lock_lock_deadlocks_total`该指标是一个死锁出现的计数器.



真正影响业务的, 不一定是死锁, 很有可能是如下几个:



#### 长事务

事务如果逻辑复杂, 就会长时间锁住数据, 导致其它线程处于等待状态, 直到`innodb_lock_wait_timeout`触发超时, 如果大量积压会出现如下情况:

- 请求排队
- 连接池打满
- 上游服务超时
- 雪崩



识别方法:

```
SELECT * FROM information_schema.innodb_trx;
```

这个表里面记录了所有当前正在进行的事务的信息, 重点关注如下字段:

```
	•	trx_started
	•	trx_rows_locked
	•	trx_mysql_thread_id 对应show processlist那个ID

👉 一个事务活很久 + 锁很多行 = 99% 事故源头
```



#### MDL锁

> **MDL 是 MySQL 为了保证表结构一致性，在访问表时自动加的“元数据锁”**, ⚠️ **MDL 不可跳过、不可关闭、不可配置**



这个我自己的理解就是, 一个事务还没结束, 这时候修改了字段.



<img width="993" height="857" alt="Image" src="https://github.com/user-attachments/assets/307f5ba7-1c06-4ff3-9d15-fb44785221ad" />

<img width="999" height="816" alt="Image" src="https://github.com/user-attachments/assets/e0563f9e-5e06-454b-9a64-407d8f5b4898" />



AI建议99%场景的ALTER操作使用**pt-online-schema-change**工具, 看来percona还是很强的, 回头再研究一下这个工具如何使用.

## 参考链接



* https://docs.percona.com/percona-toolkit/pt-deadlock-logger.html

  









