#### 背景介绍

上周六我把公司生产环境的K8S集群进行了升级, 从1.24升级到了1.26. 升级完以后收到了很多的ZK报警, 一会儿挂了然后马上就又恢复了, 如下图:
![image](https://github.com/user-attachments/assets/246677fc-fd13-483a-94cf-be3e627ca494)

我以为跟升级K8S有关系, 我就给阿里云提工单了, 我把我们的情况如实描述了一下:

1. 我们的zookeeper监控使用的是prometheus的blackbox的tcp_connect模块进行的TCP端口的监控, prometheus服务和blackbox服务部署在ACK中, zookeeper部署在ACK以外的相同VPC下的ECS中.
2. 后来经过验证, 我们发现报警的时候从POD中访问zookeeper那台服务器的所有TCP端口都是不通的, 我们测试了好多个POD都是类似现象. 我们的zookeeper有3个节点, 目前出问题的是固定的2个节点, 有一个节点是没出过类似问题的.
3. 出问题的时候, 不仅仅连不上ZK, 是ZK所在的节点的所有端口都连不上
4. 出问题的时候在ACK以外VPC以内的服务器上连接是没问题的
5. 出问题的时候可以连上百度

![image](https://github.com/user-attachments/assets/b43a774e-a4f5-4185-8206-b2250ebb107e)
![image](https://github.com/user-attachments/assets/a5a4690d-768f-4c86-b357-ffaedc8ed5d6)


#### 问题解决

经过大改半个小时的研究, 阿里云的技术支持给了答案, 罪魁祸首的是虚拟机上的一个内核参数的设置:

```
net.ipv4.tcp_tw_recycle = 1
```

应该把这个参数设置为`0`


永久修改的方式为:

1. vim编辑/etc/sysctl.conf修改
2. 执行`sysctl - p`生效
3. 执行验证`cat /proc/sys/net/ipv4/tcp_tw_recycle`


这个参数在NAT网络下就会出现服务端无响应的现象.

这个参数在Linux4版本中已经去掉了, 后续应该不会遇到类似问题了, 以后的服务器都会逐渐采用阿里云的系统了, 系统内核版本都是5.

#### 参考

* https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4396e46187ca5070219b81773c4e65088dac50cc
